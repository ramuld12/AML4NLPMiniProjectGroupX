{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10c5595",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3c9647e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:24.171305Z",
     "start_time": "2025-11-19T14:19:12.480598Z"
    }
   },
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:24.195276Z",
     "start_time": "2025-11-19T14:19:24.187658Z"
    }
   },
   "cell_type": "code",
   "source": "import sys; print(sys.executable)",
   "id": "93ee04d94d1b7046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmus\\anaconda3\\envs\\AML4NLP\\python.exe\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d9409704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:31.675665Z",
     "start_time": "2025-11-19T14:19:24.923001Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "model_name = \"bert-base-cased\"\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100))      \n",
    "test_dataset = dataset[\"test\"]          \n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 100\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "03fb4af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:32.368177Z",
     "start_time": "2025-11-19T14:19:31.700676Z"
    }
   },
   "source": [
    "# Load tokenizer and model\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6e1b7261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:32.385317Z",
     "start_time": "2025-11-19T14:19:32.380833Z"
    }
   },
   "source": [
    "def preprocess_datasets(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:33.012457Z",
     "start_time": "2025-11-19T14:19:32.400731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode splits and remove column \"text\"\n",
    "\n",
    "encoded_train = train_dataset.map(preprocess_datasets, batched=True)\n",
    "encoded_test = test_dataset.map(preprocess_datasets, batched=True)\n",
    "encoded_train = encoded_train.remove_columns([\"text\"])\n",
    "encoded_test = encoded_test.remove_columns([\"text\"])"
   ],
   "id": "5be4c24f8cdeaaaa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:33.031771Z",
     "start_time": "2025-11-19T14:19:33.024762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_train = encoded_train.with_format(\"torch\")\n",
    "encoded_test = encoded_test.with_format(\"torch\")"
   ],
   "id": "99b99f2a9fefbe27",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:36.877042Z",
     "start_time": "2025-11-19T14:19:33.045572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
    "    }\n"
   ],
   "id": "5d97290e3594a022",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:19:36.945239Z",
     "start_time": "2025-11-19T14:19:36.893450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_cased_output\",\n",
    "    eval_strategy=\"no\",       # no eval during training\n",
    "    save_strategy=\"no\",             # don't save checkpoints each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train, \n",
    "    # no eval_dataset for now\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,  \n",
    ")"
   ],
   "id": "a874f48114bedaa8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmus\\AppData\\Local\\Temp\\ipykernel_24928\\2567200792.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:22:53.531967Z",
     "start_time": "2025-11-19T14:19:36.958285Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "e6b35566d14280ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmus\\anaconda3\\envs\\AML4NLP\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 03:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26, training_loss=0.6740114505474384, metrics={'train_runtime': 196.4005, 'train_samples_per_second': 1.018, 'train_steps_per_second': 0.132, 'total_flos': 26311105536000.0, 'train_loss': 0.6740114505474384, 'epoch': 2.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:22:54.183655Z",
     "start_time": "2025-11-19T14:22:53.618978Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model(\"bert_cased\")",
   "id": "54d72fa32a62253",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:23:15.828053Z",
     "start_time": "2025-11-19T14:22:54.195498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_results = trainer.evaluate(encoded_test.shuffle(seed=42).select(range(100)))\n",
    "print(test_results)"
   ],
   "id": "91bf0c7fad57d87f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:18]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.665762186050415, 'eval_accuracy': 0.63, 'eval_f1': 0.6228750901040058, 'eval_runtime': 21.5433, 'eval_samples_per_second': 4.642, 'eval_steps_per_second': 0.325, 'epoch': 2.0}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50cd7cbbeb281cbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d23ca13b1525f42a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML4NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
