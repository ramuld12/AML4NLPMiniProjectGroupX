{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10c5595",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3c9647e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T14:45:30.933827Z",
     "start_time": "2025-11-27T14:45:30.929251Z"
    }
   },
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T14:45:34.266833Z",
     "start_time": "2025-11-27T14:45:34.259104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ],
   "id": "93ee04d94d1b7046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d9409704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T14:45:43.397647Z",
     "start_time": "2025-11-27T14:45:37.208838Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "train_validation_dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_validation_dataset[\"train\"]\n",
    "validation_dataset = train_validation_dataset[\"test\"]\n",
    "test_dataset = dataset[\"test\"]          \n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(validation_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 22500\n",
      "Validation size: 2500\n",
      "Test size: 25000\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T14:54:54.870823Z",
     "start_time": "2025-11-27T14:54:54.863169Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5e4e6763062e7496",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T15:00:39.356941Z",
     "start_time": "2025-11-27T15:00:39.349297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_datasets(tokenizer):\n",
    "    def preprocess_datasets(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=\"longest\"\n",
    "        )\n",
    "    encoded_train = train_dataset.map(preprocess_datasets, batched=True)\n",
    "    encoded_validation = validation_dataset.map(preprocess_datasets, batched=True)\n",
    "    encoded_test = test_dataset.map(preprocess_datasets, batched=True)\n",
    "    \n",
    "    encoded_train = encoded_train.remove_columns([\"text\"])\n",
    "    encoded_validation = encoded_validation.remove_columns([\"text\"])\n",
    "    encoded_test = encoded_test.remove_columns([\"text\"])\n",
    "    \n",
    "    encoded_train = encoded_train.with_format(\"torch\")\n",
    "    encoded_validation = encoded_validation.with_format(\"torch\")\n",
    "    encoded_test = encoded_test.with_format(\"torch\")\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    return encoded_train, encoded_validation, encoded_test, data_collator\n",
    "    "
   ],
   "id": "c7d4016355f64b0b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T15:00:49.285412Z",
     "start_time": "2025-11-27T15:00:41.329246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n"
   ],
   "id": "5d97290e3594a022",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T15:00:49.297875Z",
     "start_time": "2025-11-27T15:00:49.291211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"]\n",
    "    }"
   ],
   "id": "3b71b7c136425053",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T15:13:24.311261Z",
     "start_time": "2025-11-27T15:13:24.304635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_test_model(model_name):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\n",
    "        model_name\n",
    "    )\n",
    "    encoded_train, encoded_validation, encoded_test, data_collator = encode_datasets(tokenizer)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{model_name}_output\",\n",
    "        eval_strategy=\"epoch\",  \n",
    "        save_strategy=\"epoch\",           \n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        logging_first_step=True,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=encoded_train, \n",
    "        eval_dataset=encoded_validation,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,  \n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"{model_name}_model\")\n",
    "    trainer.save_metrics(f\"{model_name}_metrics\")\n",
    "    trainer.evaluate(encoded_test)\n",
    "    return trainer"
   ],
   "id": "a874f48114bedaa8",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T15:13:24.729305Z",
     "start_time": "2025-11-27T15:13:24.721441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model names\n",
    "model_name_uncased = \"bert-base-uncased\"\n",
    "model_name_cased = \"bert-base-cased\""
   ],
   "id": "c99ea316546dd99b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-27T15:13:26.352510Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_cased = train_and_test_model(model_name_cased)",
   "id": "409db31b05c23f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='28130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   16/28130 00:05 < 3:18:56, 2.36 it/s, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer_cased = train_and_test_model(model_name_uncased)",
   "id": "acc4cc3f26a04ca2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML4NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
