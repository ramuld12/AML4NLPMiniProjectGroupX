{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10c5595",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3c9647e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:41.350583Z",
     "start_time": "2025-11-28T12:09:27.160237Z"
    }
   },
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:41.426066Z",
     "start_time": "2025-11-28T12:09:41.377216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ],
   "id": "93ee04d94d1b7046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device name: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Dataset",
   "id": "961a5e587b825701"
  },
  {
   "cell_type": "code",
   "id": "d9409704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:48.528763Z",
     "start_time": "2025-11-28T12:09:42.074632Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "train_validation_dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_validation_dataset[\"train\"]\n",
    "validation_dataset = train_validation_dataset[\"test\"]\n",
    "test_dataset = dataset[\"test\"]          \n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(validation_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 22500\n",
      "Validation size: 2500\n",
      "Test size: 25000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing of the dataset",
   "id": "295b9a2a0c9e84ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:48.561374Z",
     "start_time": "2025-11-28T12:09:48.553401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_datasets(tokenizer):\n",
    "    def preprocess_datasets(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=\"longest\"\n",
    "        )\n",
    "    encoded_train = train_dataset.map(preprocess_datasets, batched=True)\n",
    "    encoded_validation = validation_dataset.map(preprocess_datasets, batched=True)\n",
    "    encoded_test = test_dataset.map(preprocess_datasets, batched=True)\n",
    "    \n",
    "    encoded_train = encoded_train.remove_columns([\"text\"])\n",
    "    encoded_validation = encoded_validation.remove_columns([\"text\"])\n",
    "    encoded_test = encoded_test.remove_columns([\"text\"])\n",
    "    \n",
    "    encoded_train = encoded_train.with_format(\"torch\")\n",
    "    encoded_validation = encoded_validation.with_format(\"torch\")\n",
    "    encoded_test = encoded_test.with_format(\"torch\")\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    return encoded_train, encoded_validation, encoded_test, data_collator\n",
    "    "
   ],
   "id": "c7d4016355f64b0b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation metrics",
   "id": "993ab6e06c2021f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:56.254277Z",
     "start_time": "2025-11-28T12:09:48.581455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n"
   ],
   "id": "5d97290e3594a022",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:56.273323Z",
     "start_time": "2025-11-28T12:09:56.265922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"]\n",
    "    }"
   ],
   "id": "3b71b7c136425053",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train and test",
   "id": "5255892b5959b42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "79b3b4f89e3b1915"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:56.296493Z",
     "start_time": "2025-11-28T12:09:56.288463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_test_model(model_name):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\n",
    "        model_name\n",
    "    )\n",
    "    encoded_train, encoded_validation, encoded_test, data_collator = encode_datasets(tokenizer)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./{model_name}_output\",\n",
    "        eval_strategy=\"epoch\",  \n",
    "        save_strategy=\"epoch\",           \n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        logging_first_step=True,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=encoded_train, \n",
    "        eval_dataset=encoded_validation,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,  \n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"{model_name}_model\")\n",
    "    test_results = trainer.evaluate(encoded_test)\n",
    "    \n",
    "    print(\"\\n====================\")\n",
    "    print(f\"Test Results for {model_name}\")\n",
    "    print(\"====================\")\n",
    "    for k, v in test_results.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "        \n",
    "    return trainer, encoded_train, encoded_validation, encoded_test, data_collator"
   ],
   "id": "a874f48114bedaa8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T12:09:56.312391Z",
     "start_time": "2025-11-28T12:09:56.307547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model names\n",
    "model_name_uncased = \"bert-base-uncased\"\n",
    "model_name_cased = \"bert-base-cased\""
   ],
   "id": "c99ea316546dd99b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T09:38:46.388484Z",
     "start_time": "2025-11-28T08:30:31.908364Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_test_model(model_name_cased)",
   "id": "409db31b05c23f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8439' max='28130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8439/28130 1:01:18 < 2:23:04, 2.29 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.287100</td>\n",
       "      <td>0.272942</td>\n",
       "      <td>0.919200</td>\n",
       "      <td>0.919199</td>\n",
       "      <td>0.925747</td>\n",
       "      <td>0.912490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.359836</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>0.919530</td>\n",
       "      <td>0.948980</td>\n",
       "      <td>0.887828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.399747</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.923964</td>\n",
       "      <td>0.946444</td>\n",
       "      <td>0.899761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 06:49]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Test Results for bert-base-cased\n",
      "====================\n",
      "eval_loss: 0.2434881031513214\n",
      "eval_accuracy: 0.92196\n",
      "eval_f1: 0.9219559990274637\n",
      "eval_precision: 0.9280902524145768\n",
      "eval_recall: 0.9148\n",
      "eval_runtime: 411.1125\n",
      "eval_samples_per_second: 60.811\n",
      "eval_steps_per_second: 3.802\n",
      "epoch: 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x295e8308350>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T13:19:52.550224Z",
     "start_time": "2025-11-28T12:09:56.331196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(trainer_uncased, \n",
    " encoded_train_uncased, \n",
    " encoded_validation_uncased, \n",
    " encoded_test_uncased, \n",
    " data_collator_uncased\n",
    " ) = train_and_test_model(model_name_uncased)"
   ],
   "id": "acc4cc3f26a04ca2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8439' max='28130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8439/28130 1:02:59 < 2:27:00, 2.23 it/s, Epoch 3/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.263237</td>\n",
       "      <td>0.924000</td>\n",
       "      <td>0.923978</td>\n",
       "      <td>0.942005</td>\n",
       "      <td>0.904535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.300888</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929999</td>\n",
       "      <td>0.936290</td>\n",
       "      <td>0.923628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.367708</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.933999</td>\n",
       "      <td>0.941034</td>\n",
       "      <td>0.926810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 06:50]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Test Results for bert-base-uncased\n",
      "====================\n",
      "eval_loss: 0.22767554223537445\n",
      "eval_accuracy: 0.93384\n",
      "eval_f1: 0.9338375542125641\n",
      "eval_precision: 0.9391804340783932\n",
      "eval_recall: 0.92776\n",
      "eval_runtime: 411.9745\n",
      "eval_samples_per_second: 60.683\n",
      "eval_steps_per_second: 3.794\n",
      "epoch: 3.0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualize Testing",
   "id": "d2e3ad5a743ad2bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "label_names = [\"Negative\", \"Positive\"]\n",
    "\n",
    "pred_output = trainer_uncased.predict(encoded_validation_uncased)\n",
    "y_true = pred_output.label_ids\n",
    "y_pred = np.argmax(pred_output.predictions, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=label_names,\n",
    "    yticklabels=label_names\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(f\"Confusion Matrix â€“ {model_name_uncased}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))\n"
   ],
   "id": "e966d930e28204e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "val_outputs = trainer_uncased.predict(encoded_validation_uncased)\n",
    "val_logits = torch.tensor(val_outputs.predictions)\n",
    "val_labels = torch.tensor(val_outputs.label_ids)\n",
    "\n",
    "# per-example cross-entropy loss\n",
    "val_loss_per_example = F.cross_entropy(val_logits, val_labels, reduction=\"none\")\n",
    "\n",
    "# convert to numpy for sorting etc.\n",
    "val_loss_per_example = val_loss_per_example.detach().cpu().numpy()\n"
   ],
   "id": "c2ded2a775dddff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# indices of top 50 highest-loss validation examples\n",
    "worst_idx = np.argsort(-val_loss_per_example)[:50]\n",
    "\n",
    "for i in worst_idx[:10]:  # print first 10 for sanity\n",
    "    original_example = validation_dataset[i]\n",
    "    print(\"VAL INDEX:\", i)\n",
    "    print(\"Label:\", original_example[\"label\"])\n",
    "    print(\"Text:\", original_example[\"text\"][:], \"...\")\n",
    "    print(\"Loss:\", val_loss_per_example[i])\n",
    "    print(\"-\" * 80)"
   ],
   "id": "37507f77203eedb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML4NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
